---
title: "Project-II-Writeup"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Read in Training Data
```{r message=FALSE, warning=FALSE, echo =FALSE}
suppressWarnings(library(knitr)) 
suppressWarnings(library(dplyr))
suppressWarnings(library(ggplot2))
suppressWarnings(library(GGally))
suppressWarnings(library(mice))
suppressWarnings(library(purrr))
suppressWarnings(library(glmnet))
suppressWarnings(library(MASS))
suppressWarnings(library(BAS))
suppressWarnings(library(tidyselect))
suppressWarnings(library(stringr))
```


```{r read-data, echo=FALSE}
set.seed(10)
load("paintings_train.Rdata")
load("paintings_test.Rdata")
```


## Manually Data Cleaning

```{r, echo=FALSE, message=FALSE, warning=FALSE}
## Remove Intuitively Useless Variables
 paintings_train_1 = paintings_train %>% 
   dplyr::select(-sale,
                 -count,
                 -price,
                 -authorstandard,
                 -winningbidder,
                 -other,
                 -Height_in,
                 -Width_in,
                 -Surface_Rect,
                 -Diam_in,
                 -Surface_Rnd,
                 -material,
                 -mat,
                 -lands_sc,
                 -lands_elem,
                 -lands_figs,
                 -lands_ment,
                 -lot,
                 -winningbiddertype,
                 -type_intermed) %>% 
   mutate(
     subject = ifelse(str_detect(paintings_train$subject,"Paysages|paysages|Paysage|paysage"), "Paysage",
           ifelse(str_detect(paintings_train$subject,"Saint|Saints|saint|saints|Notre Seigneur|NS|Notre-Seigneur|N.S.|JC|J.C.|Jesus-Christ|Jesus Christ|Assomption|Vierge|vierge|Vierges|vierges|martyre|Martyre"), "Saint",
           ifelse(str_detect(paintings_train$subject,"Portrait|Portraits|portrait|portraits"), "Portrait",
           ifelse(str_detect(paintings_train$subject,"Marine|marine|Marines|marines"), "Marine",
           ifelse(str_detect(paintings_train$subject,"Bustes|bustes|Buste|buste"), "Buste", 
           ifelse(str_detect(paintings_train$subject,"Fruits|fruits|Fruit|fruit|Fleurs|flures|Fleur|fleur|feuille|Feuille|feuilles|Feuilles"), "Fruit$Flower", 
           ifelse(str_detect(paintings_train$subject,"Sujets|sujets|Sujet|sujet"), "Sujet", 
           ifelse(str_detect(paintings_train$subject,"Hommes|Homme|hommes|homme|L'Homme|Femmes|Femme|femmes|femme|Cavaliers|cavaliers|Cavalier|cavalier|Enfants|enfants|Enfant|enfant|L'Enfant|L'enfant|Mariage|mariage|Dame|Dames|dame|dames|Marchande|Marchand|marchand|marchande|Officier|Officiers|officier|officiers"), "People",
           ifelse(str_detect(paintings_train$subject,"Arch|Architecture|Architectures|architecture|architectures|interieur|Interieur|L'interieur|L'Interieur"), "Arch", 
           ifelse(str_detect(paintings_train$subject,"bataille|Bataille|batailles|Batailles|Combat"), "Battle",
           ifelse(str_detect(paintings_train$subject,"Adoration|adoration|Adorations|adoration|L'Adoration|L'adoration|Amour|L'Amour|L'amour"), "Adoration", "other"))))))))))) %>% as.factor(.),
    

     author = ifelse(str_detect(paintings_train$author,
                                "David Teniers|David Tesniers|David T\x8eniers"), "David Teniers", 
          ifelse(str_detect(paintings_train$author,
                            "Francois Boucher|Fran\x8dois Boucher|F. Boucher"), "Francois Boucher", 
          ifelse(str_detect(paintings_train$author,
                            "Philippe Wouvermans|Philippe Wouwermans|d'apr\x8fs P. Wouvermans|Ph. Vouvermans|Philippe Wouermans|Philippe Wouwerman"), "Philippe Wouvermans",
          ifelse(str_detect(paintings_train$author,
                            "Charles de la Fosse|Ch. De la Fosse| Charles de LaFosse|C. la Fosse"), "Charles de la Fosse",
          ifelse(str_detect(paintings_train$author,"French"), "French",
          ifelse(str_detect(paintings_train$author,"Gasparo Van Vitelle"), "Gasparo Van Vitelle",
          ifelse(str_detect(paintings_train$author,"Rosalba Carriera"), "Rosalba Carriera", 
          ifelse(str_detect(paintings_train$author,"Nicolas Poussin|N. Poussin"), "Nicolas Poussin",
          ifelse(str_detect(paintings_train$author,"Gaspard Netscher|G. Netscher"), "Gaspard Netscher",
          ifelse(str_detect(paintings_train$author,"Nicolas Berghem|N. Berghem"), "Nicolas Berghem", "other")))))))))) %>% as.factor(.),
     
     #authorlevel = as.factor(authorlevel),
     #price = as.integer(price),
     dealer = as.factor(dealer),
     origin_author = as.factor(origin_author),
     origin_cat = as.factor(origin_cat),
     school_pntg = ifelse(school_pntg %in% c("A", "X"), "X", school_pntg) %>% as.factor(.),
     authorstyle = ifelse(authorstyle %in% c("n/a", ""), 0, 1) %>% as.factor(),
     #winningbiddertype = ifelse(winningbiddertype %in% c("n/a", ""), "X", winningbiddertype) %>% as.factor(),
     endbuyer = ifelse(endbuyer %in% c("n/a", ""), "X", endbuyer) %>% as.factor(),
     materialCat = ifelse(materialCat %in% c("n/a", ""), "other", materialCat) %>% as.factor(),
     Shape = ifelse(Shape %in% c("round", "roude"), "round",
                    ifelse(Shape %in% c("oval", "ovale"), "oval",
                           ifelse(Shape == "squ_rect", "squ_rect", "other"))) %>% as.factor(),
     artistliving = as.factor(artistliving),
     diff_origin = as.factor(diff_origin),
     engraved = as.factor(engraved),
     original = as.factor(original),
     prevcoll = as.factor(prevcoll),
     othartist = as.factor(othartist),
     paired = as.factor(paired),
     figures = as.factor(figures),
     lrgfont = as.factor(lrgfont),
     relig = as.factor(relig),
     landsALL = as.factor(landsALL),
     arch = as.factor(arch),
     mytho = as.factor(mytho),
     peasant = as.factor(peasant),
     othgenre = as.factor(othgenre),
     singlefig = as.factor(singlefig),
     portrait = as.factor(portrait),
     still_life = as.factor(still_life),
     discauth = as.factor(discauth),
     history = as.factor(history),
     allegory = as.factor(allegory),
     pastorale = as.factor(pastorale),
     finished = as.factor(finished)
   ) %>%  
   .[,c(8, 1:7, 9:39)]

```

## Package Imputation
```{r message=FALSE, warning=FALSE, echo=FALSE}
micetest = mice::mice(paintings_train_1, printFlag = FALSE)
paintings_train_2 = mice::complete(micetest) %>% 
  mutate(Interm = as.factor(Interm))
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
paintings_test_1 = paintings_test %>% 
   dplyr::select(-sale,
                 -count,
                 -price,
                 -authorstandard,
                 -winningbidder,
                 -other,
                 -Height_in,
                 -Width_in,
                 -Surface_Rect,
                 -Diam_in,
                 -Surface_Rnd,
                 -material,
                 -mat,
                 -lands_sc,
                 -lands_elem,
                 -lands_figs,
                 -lands_ment,
                 -lot,
                 -winningbiddertype,
                 -type_intermed) %>% 
   mutate(
     subject = ifelse(str_detect(paintings_test$subject,"Paysages|paysages|Paysage|paysage"), "Paysage",
           ifelse(str_detect(paintings_test$subject,"Saint|Saints|saint|saints|Notre Seigneur|NS|Notre-Seigneur|N.S.|JC|J.C.|Jesus-Christ|Jesus Christ|Assomption|Vierge|vierge|Vierges|vierges|martyre|Martyre"), "Saint",
           ifelse(str_detect(paintings_test$subject,"Portrait|Portraits|portrait|portraits"), "Portrait",
           ifelse(str_detect(paintings_test$subject,"Marine|marine|Marines|marines"), "Marine",
           ifelse(str_detect(paintings_test$subject,"Bustes|bustes|Buste|buste"), "Buste", 
           ifelse(str_detect(paintings_test$subject,"Fruits|fruits|Fruit|fruit|Fleurs|flures|Fleur|fleur|feuille|Feuille|feuilles|Feuilles"), "Fruit$Flower", 
           ifelse(str_detect(paintings_test$subject,"Sujets|sujets|Sujet|sujet"), "Sujet", 
           ifelse(str_detect(paintings_test$subject,"Hommes|Homme|hommes|homme|L'Homme|Femmes|Femme|femmes|femme|Cavaliers|cavaliers|Cavalier|cavalier|Enfants|enfants|Enfant|enfant|L'Enfant|L'enfant|Mariage|mariage|Dame|Dames|dame|dames|Marchande|Marchand|marchand|marchande|Officier|Officiers|officier|officiers"), "People",
           ifelse(str_detect(paintings_test$subject,"Arch|Architecture|Architectures|architecture|architectures|interieur|Interieur|L'interieur|L'Interieur"), "Arch", 
           ifelse(str_detect(paintings_test$subject,"bataille|Bataille|batailles|Batailles|Combat"), "Battle",
           ifelse(str_detect(paintings_test$subject,"Adoration|adoration|Adorations|adoration|L'Adoration|L'adoration|Amour|L'Amour|L'amour"), "Adoration", "other"))))))))))) %>% as.factor(.),
     
     
     
     author = ifelse(str_detect(paintings_test$author,
                                "David Teniers|David Tesniers|David T\x8eniers"), "David Teniers", 
          ifelse(str_detect(paintings_test$author,
                            "Francois Boucher|Fran\x8dois Boucher|F. Boucher"), "Francois Boucher", 
          ifelse(str_detect(paintings_test$author,
                            "Philippe Wouvermans|Philippe Wouwermans|d'apr\x8fs P. Wouvermans|Ph. Vouvermans|Philippe Wouermans|Philippe Wouwerman"), "Philippe Wouvermans",
          ifelse(str_detect(paintings_test$author,
                            "Charles de la Fosse|Ch. De la Fosse| Charles de LaFosse|C. la Fosse"), "Charles de la Fosse",
          ifelse(str_detect(paintings_test$author,"French"), "French",
          ifelse(str_detect(paintings_test$author,"Gasparo Van Vitelle"), "Gasparo Van Vitelle",
          ifelse(str_detect(paintings_test$author,"Rosalba Carriera"), "Rosalba Carriera", 
          ifelse(str_detect(paintings_test$author,"Nicolas Poussin|N. Poussin"), "Nicolas Poussin",
          ifelse(str_detect(paintings_test$author,"Gaspard Netscher|G. Netscher"), "Gaspard Netscher",
          ifelse(str_detect(paintings_test$author,"Nicolas Berghem|N. Berghem"), "Nicolas Berghem", "other")))))))))) %>% as.factor(.),
     
     #authorlevel = as.factor(authorlevel),
     #price= as.integer(logprice),
     dealer = as.factor(dealer),
     origin_author = as.factor(origin_author),
     origin_cat = as.factor(origin_cat),
     school_pntg = as.factor(school_pntg),
     authorstyle = ifelse(authorstyle %in% c("n/a", ""), 0, 1) %>% as.factor(),
     #winningbiddertype = ifelse(winningbiddertype %in% c("n/a", "", "EB"), "X", winningbiddertype) %>% as.factor(),
     endbuyer = ifelse(endbuyer %in% c("n/a", ""), "X", endbuyer) %>% as.factor(),
     materialCat = ifelse(materialCat %in% c("n/a", ""), "other", materialCat) %>% as.factor(),
     Shape = ifelse(Shape %in% c("round", "roude"), "round",
                    ifelse(Shape %in% c("oval", "ovale"), "oval",
                           ifelse(Shape == "squ_rect", "squ_rect", "other"))) %>% as.factor(),
     artistliving = as.factor(artistliving),
     diff_origin = as.factor(diff_origin),
     engraved = as.factor(engraved),
     original = as.factor(original),
     prevcoll = as.factor(prevcoll),
     othartist = as.factor(othartist),
     paired = as.factor(paired),
     figures = as.factor(figures),
     lrgfont = as.factor(lrgfont),
     relig = as.factor(relig),
     landsALL = as.factor(landsALL),
     arch = as.factor(arch),
     mytho = as.factor(mytho),
     peasant = as.factor(peasant),
     othgenre = as.factor(othgenre),
     singlefig = as.factor(singlefig),
     portrait = as.factor(portrait),
     still_life = as.factor(still_life),
     discauth = as.factor(discauth),
     history = as.factor(history),
     allegory = as.factor(allegory),
     pastorale = as.factor(pastorale),
     finished = as.factor(finished)
   ) %>%  
   .[,c(8, 1:7, 9:39)]

```

## Package Imputation
```{r message=FALSE, warning=FALSE, echo=FALSE}
micetest = mice::mice(paintings_test_1, printFlag = FALSE)
paintings_test_2 = mice::complete(micetest) %>% 
  mutate(Interm = as.factor(Interm))
```

## 1. Introduction (1 point if improved from before)

In this study, the auction prices of paintings in 18th century Paris were examined. Specifically, we wish to understand the variables which affect the prices of the paintings, and then be able to predict auction prices based on characteristics of a certain painting. By fitting an appropriate model, we will also be creating a tool to help decide whether specific paintings that are either underpriced or overpriced given their realization of the covariates that were included in the model.

One of the main challenges in building this model is to narrow down the number of covariates from the 59 candidates in the original data set to less than 20 in the final model. This must be done in such a way that an undue amount of bias is not introduced, and overfitting is avoided. Another challenge is to properly deal with the messiness of the data, including both missingness, covariates with a very large number of levels, multicollinearity in the data, and discrepancies in data entries (e.g. same category marked differently).

The ability to explain the results and provide some recommendations to individuals without statistical background is equally important and challenging, since the primary audience for this analysis is intended to be art historians. The goal was therefore to balance predictive performance, model simplicity, and interpretability in order to create a pricing model for artwork in 18th century France.

## 2. Exploratory data analysis (1 point if improved from before): 
   
## A) Data summary & cleaning
To start with, we looked at the summary of the original trainig data. There are few numeric variables and a lot of binary variables. Some variables, such as `Interm`, `Surface`, `Height_in` etc. have mising values, which need to be taken care of. The followings steps are how we cleaned the data: 

a. The first step we did was to get rid of intuitivelly useless variables to reduce dimention, including: `lot`, `sale`, `price`, `count`, `subject`, `authorstandard`, `author`, `winningbidder`, and `other`. From the summary table, the `count` variable has all 1's; the `other` variable does not convey useful information; the other variables, such as `names` and `subjects`, are not useful in predicting the response variable (such as names). From the table of unique values we can see that some variables have thousands of unique values. Therefore, we can remove them in the first step.

b. By further screening the variables, we found out that `Surface` and `Surface_Rnd`, `Surface_Rect` are correlated, which are based on the value of `Height_in`, `Width_in`, and `Diam_in`. We decided to use `Surface` in our initial model. The same issue happened to `material`, `mat`, and `materialCat`. The latter one recodes the previous one. Therefore, we used `materialCat`. We applied the same strategy to keep `landsALL` and get rid of other variables related with landscape. 

c. For those variables that have multiple levels, to be consistent with how the data was originally coded, we recoded the missing levels as "X", which stands for "no information". For `materialCat` and `Shape`, since there are so many levels, we grouped some levels with few observations together, coded as "other" group. The rest binary vairables are changed into factor.

d. Then we dealt with the missing values in `Surface` and `Interm`. We used the package "mice" to address this problem, which uses the observed values in the dataset to impute the missing values. It prevents directly throwing away the missing values, which results in lossing a large amont of information for prediction.

e. The variable `subject` also contains a lot of levels, potentially with many observations representing the same thing but simply expressed in different ways (i.e. different spellings, letter capitalization). Strings of the same meaning are detected from subjects and recatogorized together. Those levels with more than 20 observations are kept while all others are put together under other.

f. On top of the previous steps, we also recategorized the authors since many authors have too few paintings but were still counted as a level in the categorical variable. Only the authors with more than 10 paintings are kept as a distinct level, and all others are merged into the `other` level. 

```{r}
kable(paintings_train_2 %>% 
  group_by(author) %>% 
  summarise(sum = n()) %>% 
  arrange(desc(sum)), align = "c")

kable(paintings_train_2 %>% 
  group_by(subject) %>% 
  summarise(sum = n()) %>% 
  arrange(desc(sum)), align = "c")
```

## B). Plots
```{r parse_df, message=FALSE, warning=FALSE, echo=FALSE}
graph_numeric = paintings_train_2 %>% 
  dplyr::select(position,
         year,
         Surface,
         nfigures)

graph_categorical = paintings_train_2 %>% 
  dplyr::select(-position,
         -year,
         -Surface,
         -nfigures,
         -logprice)
```
Then we analyed the relationship between those left features and the response variable. With the scatter plots, we can roughly determine which variables can be put into the initial model. For categorical variables, we want to check if the `logprice` spans different ranges in different levels. For numeric variables, we want to check if there is a clear relationship between them and `logprice`.  

For numeric variables, we see that `Surface` and `nfigures` seem to show some weak but positive relationship with `logprice`. Since there are several extremely large values in `position` (potentially outliers), it is hard to see that real pattern between the majority of points and `logprice`. But we'll keep it in the model first.

```{r num_eda}
## numeric
par(mfrow = c(2, 2))
for (i in 1:ncol(graph_numeric)){
  plot(y = paintings_train_2$logprice, 
       x = graph_numeric[,i],
       ylab = "logprice",
       xlab = names(graph_numeric)[i])
}

```

Since there are 33 categorical variables, we don't show the boxplots for all of them. But applied the same method to check all the categorical variables. The following variables show some differences in `logprice` at different levels (not considering the magnitude of the difference at this time): `subject`, `author`, `dealer`, `origin_author`, `origin_cat`, `school_pntg`, `diff_origin`, `authorstyle`, `endbuyer`, `Interm`, `Shape`, `materialCat`, `engraved`, `prevcoll`, `figures`, `finished`, `Irgfont`, `othgenre`, `discauth`, and `still_life`.

```{r cat_eda}
## categorical
par(mfrow = c(2,3))
for (i in 1:12){
  boxplot(paintings_train_2$logprice ~ graph_categorical[,i],
          ylab = "logprice",
          xlab = names(graph_categorical)[i])
}

```

If we were to choose best predictive variables for predicting, we would consider the magnitude of differences and the strength of relationships. The 10 variables we choose are: `Surface`, `subjetc`, `author`, `dealer`, `school_pntg`, `diff_origin`, `authorstyle`, `endbuyer`, `Interm`, `prevcoll`, `engraved`, `Irgfont`.

For numeric variables, we note that `Surface` and `nfigures` appear to have a weak but positive relationship with `logprice`. Since there are several extremely large values in `position` (potential outliers), it is difficult to know if there is a truly useful relationship here between the majority of points and `logprice`. But we will keep it in the initial model for now.



##3. Discussion of preliminary model Part I (5 points)

The overall characteristics of the model that we built in part I were: relatively lower bias, reasonable coverage and higher rmse, comparing to other teams. The methodologies used to conclude at the first model included EDA analyses, BAS, stepwise selection with AIC and BIC, which doesn't do an exhausive search for all possible models, thus the true model and the best model for prediction might not have been captured.

Since there's inherently a trade off between  bias and rmse, it is reasonale that we were able to get a bias value on the lower side while rmse unfortunately was on the higher end. There is room for both values, however, to be improved with a better model, potentially a model other than a linear one, or through deeper data cleaning. Next, besides more data cleaning and re-coding, we will be focusing on models like tree/forest methods, as well as more development on linear models.


## 4.  Development of the final model
### Final model
```{r, echo=FALSE, message=FALSE, warning=FALSE}
ols.2 = lm(logprice ~ Shape + school_pntg
           + dealer*Interm + dealer*paired + dealer*artistliving + dealer*diff_origin
           + artistliving*endbuyer + artistliving*finished + artistliving*year
           + diff_origin*Surface + diff_origin*portrait  + diff_origin*still_life + diff_origin*prevcoll
           + endbuyer*Surface + endbuyer*paired + endbuyer*year
           + authorstyle*portrait
           + Interm*lrgfont
           + paired*lrgfont + paired*subject + paired*discauth + paired*author
           + finished*discauth
           + lrgfont*discauth
           + prevcoll*dealer + prevcoll*school_pntg + prevcoll*Interm
             ,data = paintings_train_2)
```

```{r}
summary(ols.2)
```

### Variables: must include an explanation

a. The base variables we chose are: `Shape`, `school_pntg`, `dealer`, `Interm`, `paired`, `artistliving`, `diff_origin`, `endbuyer`, `finished`, `year`, `Surface`, `portrait`, `still_life`, `prevcoll`, `authorstyle`, `lrgfont`, `discauth`, `subject` and `author`.

b. The interactions we used include: `dealer*Interm`, `dealer*paired`, `dealer*artistliving`, `dealer*diff_origin`, `artistliving*endbuyer`, `artistliving*finished`, `artistliving*year`, `diff_origin*Surface`, `diff_origin*portrait`, `diff_origin*still_life`, `diff_origin*prevcoll` `endbuyer*Surface`, `endbuyer*paired`, `endbuyer*year`, `authorstyle*portrait`, `Interm*lrgfont`, `paired*lrgfont`, `paired*subject`, `paired*discauth`, `paired*author`, `finished*discauth`, `lrgfont*discauth`, `prevcoll*dealer`, `prevcoll*school_pntg`, and `prevcoll*Interm`.

c. Partial Explnations:

* dealer: the type of dealer that the auction went through significantly affects the price of the painting. For example, compared with dealer J, the average price from dealer L is `179% higher`. (Same interpretation for dealer P and R, with different coefficients)

* finished: if the painting is noted for being highly finished, the selling price on average is `69.76% higher` than when the painting is not noted for being highly finished.

* prevcoll: when the previous owner is mentioned, the average selling price is `128.0% higher` than when the previous owner is not mentioned.

* lrgfont: when the dealer devotes an additional paragraph, the average selling price is `124.9% higher` than when there is no additional paragraph.

* authorstyle: when the author's name is introduced, the average selling price is expected to be `88.39% lower` than when the author's name is not introduced.

* author: which author painted the painting also has some influence on the price. Compared with author Charles de la Fosse, author David Teniers' paintings are `80.57% higher` in price on average. Author Nicolas Berghem's paintings are `181.4% higher` in price on average. 

* dealer&Interm interaction: when an intermediary is present, which the price of the auctioned paintings differs significantly among different dealers. For instance, if the dealer is R and an intermediary is used, the average selling price is `107.0% higher` than when the dealer is J with an intermediary.

* finished*discauth: given that the painting is noted for being highly finished, when the dealer engages with authenticity, the average price is expected to be `76.2% higher`.

* diff_origin:still_life: given that the origin of painting based on nationality of artist is different from the origin of painting based on dealer's classification, if the description indicates still life elements, the price is expected to be `-112.8% lower`.


### Variable selection/shrinkage:

a. Linear Model

The linear model from part I does a fairly good job in predicting. Therefore, after adding two more variables in the dataset, we decided to refine the linear model first. The plan was to add new features and interactions into the model, hoping to potentially explain more variation in the response variable. Similar as the process in part I, we applied BMA (Bayesian Model Averaging) to select the base variables that have high posterior probabilities and include them in the initial model. Then we tested all possible interactions and used AIC to select interactions that are good for predicting. However, the output from AIC contain too many interactions, which might lead to the problem of overfitting. Additionally, it contains some interactions with coefficients as NA, and some that do not make sense at all. Therefore I manually removed them and kept twisting around the rest features, which led to the best final linear model in terms of the lowest RMSE.

b. Tree Model

Since we have many categorical variables, as in nature, a tree-based model would be appropriate in addressing the interactions to explain the response variable. We tested two tree models: random forest and boosting (bagging does not work in our case as we have 39 variables, which is beyond the limit of possible selection candidates at each node). As for random forest, we used $mtry = 13$ as this is a regression problem. For boosting, we used 5000 trees and tried different interaction depth (4, 6, 8, 10). Both methods do better job than the linear model from part I, but not as good as the linear model generated above. 

c. Poisson&Negative Binomial Regression

The nature of auction price is integer. Even though not strictly count data, but could be treated in such way so that we can use poisson&negative binomial regression. We trained the tested the poisson model first. With all the vairiables included (even with all the interactionss), the residual deviance is 100 times higher than the residual degrees of freedom. We concluded that the poisson model s not appropriate and proceeded with negative binomial model. The RMSE is not better than the linear model is part I (even with all the interactions) and there is still the problem of over-dispersion. 

d. Xgboost
## Added some description here

Comparing all the models we fitted above, we conclude that the linear model has the best performance in terms of predicting (lowest rmse). The linear model was relatively more complex than the one in part I, resuting in some loss in predictability. However, it is still more interpretable than tree-based models. Therefore, we concluded that the best model is the linear model.

```{r}
plot(ols.2)
```

### Residual: must include a residual plot and a discussion
The residual plot looks fairly good. There seems to have a pattern that the variance is slightly higher with fitted value around 5 and a little lower at the two tails. But in general, the constant vairance assumption is satisfied. The normality assumption is well satisfied from normal qq-plot, with several observations slightly scattered away on the two sides. 


### discussion of how prediction intervals obtained
```{r}
PI = data.frame(exp(predict(ols.2, 
                 newdata=paintings_test_2, 
                 interval = "pred")))
kable(PI, digits = 3, align = "c", caption = "Prediction Interval")
```

Since we are still using the linear regression model, we used `predict` function with `interval = "pred"` argument to obtain the prediction interval. 

## 5. Assessment of the final model (25 points)


### Model evaluation: must include an evaluation discussion

### Model testing : must include a discussion

### Model result: must include a selection and discussion of the top 10 valued  paintings in the validation data.

## 6. Conclusion (10 points): must include a summary of results and a discussion of things learned. Optional what would you do if you had more time.
